{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f67f0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn import init\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "import torch.utils.data as data\n",
    "from torchvision.transforms import transforms \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from optimizer import LARS\n",
    "from PIL import Image\n",
    "import torchvision as tv\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce8ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.name = 'CIFAR_AUTO'   \n",
    "        self.dataset_name = 'CIFAR-10-C'\n",
    "        self.dataroot ='../DATASETS/'+self.dataset_name\n",
    "        \n",
    "        self.save = './CHECKPOINT/' + self.name\n",
    "        self.model_path = self.save + '/models'\n",
    "        self.decode_path = self.save + '/decoded_results'\n",
    "        self.val_path = self.save + '/val_results'\n",
    "        self.test_path = self.save + '/test_results'\n",
    "        self.runs = self.save + '/runs'\n",
    "        \n",
    "        self.seed =1\n",
    "        self.input_nc = 3                    # input channel number\n",
    "        self.output_nc = 3                   # output channel number\n",
    "        \n",
    "        #dataset\n",
    "        self.shuffle_dataset=True\n",
    "        self.batch_size = 256\n",
    "        self.input_shape = '32,32,3'\n",
    "        self.num_workers =16\n",
    "\n",
    "        # optimization\n",
    "        self.base_learning_rate = 0.02\n",
    "        self.learning_rate = self.base_learning_rate/self.batch_size\n",
    "        self.max_lr = self.learning_rate * self.batch_size\n",
    "        self.learning_rate_min= 8e-4\n",
    "        self.Base_momentum=0.99\n",
    "        self.weight_decay= 5e-4\n",
    "        self.epochs=1000\n",
    "        self.warmup_epochs=30                  \n",
    "        \n",
    "               \n",
    "        os.makedirs(self.save, exist_ok=True)\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "        os.makedirs(self.decode_path, exist_ok=True)\n",
    "        os.makedirs(self.val_path, exist_ok=True)\n",
    "        os.makedirs(self.test_path, exist_ok=True)\n",
    "        os.makedirs(self.runs, exist_ok=True)\n",
    "        \n",
    "opt=Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDS(data.Dataset):\n",
    "    def __init__(self, noise,transform):\n",
    "        x_paths = []\n",
    "        path = opt.dataroot\n",
    "        \n",
    "        self.transform=transform\n",
    "        self.xs = []\n",
    "        self.ys = None\n",
    "        \n",
    "        for n in noise:\n",
    "            pth = os.path.join(path,n)\n",
    "            x_paths.append(pth)\n",
    "            \n",
    "        for x_path in list(x_paths):\n",
    "            print(f'loaded: {x_path}')\n",
    "            self.xs.append(np.load(x_path))\n",
    "            \n",
    "#             self.xs = torch.from_numpy(np.load(x_path))\n",
    "        self.xs = np.array(self.xs)\n",
    "        self.xss = np.concatenate(self.xs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xss)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.xss[idx]   \n",
    "        image = Image.fromarray(img.astype('uint8'), 'RGB')\n",
    "        image = self.transform(image)\n",
    "#         print(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = ['frost.npy','elastic_transform.npy','impulse_noise.npy','shot_noise.npy','zoom_blur.npy'] # small subset of actual dataset\n",
    "\n",
    "data_transforms = transforms.Compose([transforms.Resize(size=eval(opt.input_shape)[0]),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize( mean=torch.tensor([0.5204, 0.5169, 0.4858]),\n",
    "                                                              std=torch.tensor([0.2487, 0.2472, 0.2654]) )\n",
    "                                        ])\n",
    "\n",
    "ds = MYDS(noise,data_transforms)\n",
    "dl = data.DataLoader(ds, batch_size=opt.batch_size, shuffle=opt.shuffle_dataset, num_workers=opt.num_workers,drop_last=True)\n",
    "print(f'loaded {len(ds)} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for img in dl:\n",
    "#         print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6059500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_mean_and_sd(loader):\n",
    "    \"\"\"Compute the mean and sd in an online fashion\n",
    "\n",
    "        Var[x] = E[X^2] - E^2[X]\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    fst_moment = torch.empty(3)\n",
    "    snd_moment = torch.empty(3)\n",
    "\n",
    "    for images in loader:\n",
    "\n",
    "        b, c, h, w = images.shape\n",
    "        nb_pixels = b * h * w\n",
    "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
    "        sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3])\n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
    "\n",
    "        cnt += nb_pixels\n",
    "\n",
    "    return fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "# mean, std = online_mean_and_sd(dl)\n",
    "# print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "            \n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "    \n",
    "        self.conv_block = UNetConvBlock(out_size, out_size, padding, batch_norm)\n",
    "    \n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "    \n",
    "        return layer[:, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])]\n",
    "    \n",
    "    def forward(self, x, bridge):\n",
    "        try:\n",
    "            up = self.up(x,output_size=bridge.size())\n",
    "        except:\n",
    "            up = self.up(x)    \n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(up)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=3,                       #in_channels (int): number of input channels\n",
    "                 out_channels=3,                      #n_classes (int): number of output channels\n",
    "                 padding=1,     \n",
    "                 depth=4,                             #depth (int): depth of the network\n",
    "                 wf=5,\n",
    "                 batch_norm=False,\n",
    "                 up_mode='upsample',                   # one of 'upconv' or 'upsample'.\n",
    "        ):                        \n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm))\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "        \n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm))\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "            \n",
    "        \n",
    "        self.last = nn.Conv2d(prev_channels, out_channels, kernel_size=1,stride=1)\n",
    "                 \n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "#         print('Encoder\\n')\n",
    "        for i, down in enumerate(self.down_path,0):\n",
    "            x = down(x)\n",
    "#             print(f'in UNET Down_path Forward {x.shape}')\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "#                 print(f'after maxpool {x.shape}')\n",
    "          \n",
    "#         print('\\n\\nDecoder\\n')\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "#             print(x.shape)\n",
    "        \n",
    "            \n",
    "        x=self.last(x)\n",
    "#         print(f'final conv {x.shape}')\n",
    "        return (x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = UNet().to(device)\n",
    "params=list(network.parameters())\n",
    "# optimizer = torch.optim.Adam(params,lr=opt.learning_rate,weight_decay=opt.weight_decay)\n",
    "optimizer = LARS(params, lr=opt.max_lr, momentum=opt.Base_momentum, weight_decay=opt.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, float(opt.epochs - opt.warmup_epochs - 1), eta_min=opt.learning_rate_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940d0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, network, optimizer,scheduler, device, opt):\n",
    "        self.model = network\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.max_epochs = opt.epochs\n",
    "        self.writer = SummaryWriter(opt.runs)\n",
    "        self.batch_size = opt.batch_size\n",
    "        self.num_workers = opt.num_workers\n",
    "        self.scheduler=scheduler\n",
    "        \n",
    "        self.num_examples = len(dl.dataset)\n",
    "        self.warmup_steps = opt.warmup_epochs * self.num_examples // opt.batch_size\n",
    "        self.total_steps = opt.epochs * self.num_examples // opt.batch_size\n",
    "        \n",
    "\n",
    "\n",
    "    def _cosine_decay(self,step):\n",
    "        return 0.5 * opt.max_lr * (1 + np.cos((step - self.warmup_steps) * np.pi / (self.total_steps - self.warmup_steps)))\n",
    "    \n",
    "    def update_learning_rate(self, step, decay='poly'):\n",
    "        \"\"\"learning rate warm up and decay\"\"\"\n",
    "        if step <= self.warmup_steps:\n",
    "            lr = opt.max_lr * step / self.warmup_steps\n",
    "        else:\n",
    "            lr = self._cosine_decay(step)\n",
    "            \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "    def weight_init(self,m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal_(m.weight)\n",
    "            init.constant_(m.bias, 0)\n",
    "\n",
    "        \n",
    "    def train(self,train_loader):\n",
    "        \n",
    "        try:\n",
    "            print(\"Loading Pretrained models\")\n",
    "            state = torch.load(os.path.join(opt.model_path, 'model.pth'),map_location=device)\n",
    "            self.model.load_state_dict(state['network_state_dict'])\n",
    "            self.optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "            print(\"Loaded pre-trained models with success.\")\n",
    "            niter=state['iter']\n",
    "            epoch_counter=state['epoch']\n",
    "            loss=state['loss']\n",
    "            print('NITER: %d | EPOCH: %d | Loss: %.3f '%(niter,epoch_counter,loss))\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"Pre-trained weights not found. Training from scratch\")\n",
    "            self.model.apply(self.weight_init)\n",
    "            niter = 0\n",
    "            epoch_counter=0\n",
    "            \n",
    "        cost = torch.nn.MSELoss()\n",
    "        for epoch in range(epoch_counter,self.max_epochs):\n",
    "            print()\n",
    "            print('==================================================================')\n",
    "            print('-------------Epoch: {}/{}------------'.format(epoch,self.max_epochs))\n",
    "            epoch_loss=0.0\n",
    "            for idx,img in enumerate(dl):\n",
    "                self.update_learning_rate(niter)\n",
    "                img = img.to(self.device)\n",
    "#                 print(img.shape)\n",
    "\n",
    "#                 if niter == 0:\n",
    "#                     grid = torchvision.utils.make_grid(img[:32])\n",
    "#                     self.writer.add_image('input_views', grid, global_step=niter)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                out = self.model(img)\n",
    "                loss = cost(out, img)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss+=loss.item()\n",
    "\n",
    "                \n",
    "                if (niter+1) % 500 == 0:\n",
    "                    print('ITER: %d | Loss: %.3f ' %(niter, loss))\n",
    "\n",
    "                self.writer.add_scalar('loss', loss, global_step=niter)\n",
    "                niter += 1\n",
    "\n",
    "            print(\"End of epoch {}\".format(epoch))\n",
    "            mean_loss = epoch_loss/len(dl)\n",
    "            print('EPOCH: %d | Loss: %.3f ' %(epoch, mean_loss))\n",
    "            with open(f'{opt.save}/logs.txt', 'a') as file:\n",
    "                file.write(str(epoch)+' '+str(mean_loss)+'\\n')\n",
    "            # save checkpoints\n",
    "            self.save_model(os.path.join(opt.model_path, 'model.pth'),loss,niter,epoch)\n",
    "            if epoch%50==0:\n",
    "                self.save_model(os.path.join(opt.model_path, f'model_{epoch}.pth'),loss,niter,epoch)\n",
    "                filename = 'decoded_%03d.png' % (epoch)\n",
    "                path = os.path.join(opt.decode_path, filename)\n",
    "                tv.utils.save_image(out.cpu().data, path, normalize=True)\n",
    "                print(f'{filename} saved.')\n",
    "#             if epoch > opt.warmup_epochs:\n",
    "#                  self.scheduler.step()\n",
    "#                 lr = self._cosine_decay(step)\n",
    "\n",
    "\n",
    "    def save_model(self, PATH,loss,niter,epoch):\n",
    "        torch.save({\n",
    "            'loss': loss,\n",
    "            'iter': niter,\n",
    "            'epoch': epoch,\n",
    "            'network_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(network=network,\n",
    "                      optimizer=optimizer,\n",
    "                      device=device,\n",
    "                      scheduler=scheduler,\n",
    "                      opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7790e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750be3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
